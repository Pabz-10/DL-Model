{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify Recommendation System - Experimentation Notebook\n",
    "\n",
    "This notebook provides a complete framework for training, evaluating, and visualizing a baseline collaborative filtering model for song recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "Install and import necessary libraries. We add `matplotlib` for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas scikit-learn tqdm matplotlib joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import joblib\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Experiment Tracking Setup\n",
    "\n",
    "We'll create a list to store the results of each experiment. This will allow us to easily compare runs and plot the outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This list will store dictionaries, each representing the results of a single experiment run.\n",
    "# Each dictionary will contain parameters (like n_components) and metrics (like precision/recall).\n",
    "experiment_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Core Functions (Data Loading, Evaluation)\n",
    "\n",
    "These are the helper functions for loading data and calculating our evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_playlist_slice(path, slice_nums=[0]):\n",
    "    \"\"\"Loads one or more JSON slice files from the dataset.\n",
    "\n",
    "    Args:\n",
    "        path (str): The absolute path to the 'data' directory of the MPD.\n",
    "        slice_nums (list): A list of integer slice numbers to load (e.g., [0, 1] for mpd.slice.0-999.json and mpd.slice.1000-1999.json).\n",
    "\n",
    "    Returns:\n",
    "        list: A list of playlist dictionaries loaded from the specified slices.\n",
    "    \"\"\"\n",
    "    all_playlists = []\n",
    "    for slice_num in slice_nums:\n",
    "        # Construct the filename for the current slice\n",
    "        filename = f'mpd.slice.{slice_num*1000}-{(slice_num+1)*1000-1}.json'\n",
    "        try:\n",
    "            # Open and load the JSON file\n",
    "            with open(os.path.join(path, filename)) as f:\n",
    "                data = json.load(f)\n",
    "                all_playlists.extend(data['playlists'])\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Warning: Slice file not found at {os.path.join(path, filename)}. Skipping.\")\n",
    "    return all_playlists\n",
    "\n",
    "def precision_at_k(k, recommendations, holdout_items):\n",
    "    \"\"\"Calculates Precision@k.\n",
    "\n",
    "    Args:\n",
    "        k (int): The number of top recommendations to consider.\n",
    "        recommendations (list): A list of recommended item URIs.\n",
    "        holdout_items (list): A list of actual relevant item URIs (ground truth).\n",
    "\n",
    "    Returns:\n",
    "        float: The Precision@k score.\n",
    "    \"\"\"\n",
    "    recs_at_k = recommendations[:k] # Take only the top k recommendations\n",
    "    # Count how many of the top k recommendations are in the holdout items\n",
    "    hits = len(set(recs_at_k) & set(holdout_items))\n",
    "    # Precision is hits divided by k (the number of recommendations made)\n",
    "    return hits / k\n",
    "\n",
    "def recall_at_k(k, recommendations, holdout_items):\n",
    "    \"\"\"Calculates Recall@k.\n",
    "\n",
    "    Args:\n",
    "        k (int): The number of top recommendations to consider.\n",
    "        recommendations (list): A list of recommended item URIs.\n",
    "        holdout_items (list): A list of actual relevant item URIs (ground truth).\n",
    "\n",
    "    Returns:\n",
    "        float: The Recall@k score.\n",
    "    \"\"\"\n",
    "    recs_at_k = recommendations[:k] # Take only the top k recommendations\n",
    "    # Count how many of the top k recommendations are in the holdout items\n",
    "    hits = len(set(recs_at_k) & set(holdout_items))\n",
    "    # Recall is hits divided by the total number of relevant items in the holdout set\n",
    "    return hits / len(holdout_items) if len(holdout_items) > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Experiment Runner\n",
    "\n",
    "This is the main function that encapsulates the entire process: data loading, preprocessing, training, and evaluation. It takes your parameters, runs the experiment, and stores the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(slice_nums, n_components, k=10):\n",
    "    \"\"\"Runs a full experiment cycle with given parameters and stores the results.\n",
    "\n",
    "    Args:\n",
    "        slice_nums (list): List of slice numbers to load for this experiment.\n",
    "        n_components (int): The number of latent factors for the TruncatedSVD model.\n",
    "        k (int): The 'k' value for Precision@k and Recall@k evaluation metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"--- Starting Experiment: Slices={slice_nums}, n_components={n_components}, k={k} ---\")\n",
    "\n",
    "    # --- 1. Data Loading --- \n",
    "    # Load playlist data from the specified slices using the global data_path\n",
    "    print(f\"Loading {len(slice_nums)} slice(s) of data...\")\n",
    "    data_path = '/Users/pabil/Downloads/spotify_million_playlist_dataset/data/'\n",
    "    playlists = load_playlist_slice(data_path, slice_nums=slice_nums)\n",
    "    if not playlists:\n",
    "        print(\"No data loaded. Aborting experiment.\")\n",
    "        return\n",
    "\n",
    "    # --- 2. Data Preprocessing & Train-Test Split --- \n",
    "    # Extract all tracks and create mappings for unique tracks and playlists\n",
    "    print(\"Preprocessing data and creating train-test split...\")\n",
    "    all_tracks = [track['track_uri'] for p in playlists for track in p['tracks']]\n",
    "    unique_tracks = sorted(list(set(all_tracks)))\n",
    "    track_to_idx = {track: i for i, track in enumerate(unique_tracks)}\n",
    "    idx_to_track = {i: track for track, i in track_to_idx.items()}\n",
    "    pid_to_idx = {p['pid']: i for i, p in enumerate(playlists)}\n",
    "\n",
    "    n_playlists = len(playlists)\n",
    "    n_tracks = len(unique_tracks)\n",
    "\n",
    "    rows, cols, test_set = [], [], {}\n",
    "    for p in playlists:\n",
    "        playlist_idx = pid_to_idx[p['pid']]\n",
    "        tracks = [t['track_uri'] for t in p['tracks']]\n",
    "        \n",
    "        # For playlists with enough tracks, hold out some for testing (20% of tracks)\n",
    "        if len(tracks) > 5:\n",
    "            np.random.shuffle(tracks)\n",
    "            num_holdout = int(len(tracks) * 0.2)\n",
    "            test_set[playlist_idx] = [uri for uri in tracks[-num_holdout:] if uri in track_to_idx] # Store holdout URIs\n",
    "            train_tracks = tracks[:-num_holdout]\n",
    "        else:\n",
    "            train_tracks = tracks\n",
    "        \n",
    "        # Populate rows and columns for the training interaction matrix\n",
    "        for track_uri in train_tracks:\n",
    "            if track_uri in track_to_idx:\n",
    "                rows.append(playlist_idx)\n",
    "                cols.append(track_to_idx[track_uri])\n",
    "\n",
    "    # Create a sparse matrix for memory efficiency, using only training interactions\n",
    "    interaction_matrix_train = csr_matrix((np.ones(len(rows)), (rows, cols)), shape=(n_playlists, n_tracks))\n",
    "\n",
    "    # --- 3. Model Training (Truncated SVD) --- \n",
    "    print(f\"Training SVD model with n_components={n_components}...\")\n",
    "    svd = TruncatedSVD(n_components=n_components, random_state=42)\n",
    "    # Fit and transform the training interaction matrix to get playlist embeddings\n",
    "    playlist_embeddings = svd.fit_transform(interaction_matrix_train)\n",
    "    # Extract track embeddings from the SVD components\n",
    "    track_embeddings = svd.components_.T\n",
    "\n",
    "    # --- 4. Recommendation Generation (KNN) --- \n",
    "    # Fit a K-Nearest Neighbors model on the track embeddings for efficient nearest neighbor search\n",
    "    knn = NearestNeighbors(n_neighbors=k*2, metric='cosine', algorithm='brute').fit(track_embeddings)\n",
    "\n",
    "    # Define a local helper function for recommending from a playlist (used during evaluation)\n",
    "    def _recommend_from_playlist_for_eval(playlist_idx_for_eval, train_matrix_for_eval, n_recs_for_eval=k):\n",
    "        # Get the indices of tracks in the user's training playlist\n",
    "        input_track_indices_for_eval = train_matrix_for_eval[playlist_idx_for_eval].indices\n",
    "        if len(input_track_indices_for_eval) == 0:\n",
    "            return []\n",
    "        \n",
    "        # Calculate the average embedding for the input playlist's tracks\n",
    "        playlist_vector_for_eval = np.mean(track_embeddings[input_track_indices_for_eval], axis=0).reshape(1, -1)\n",
    "        \n",
    "        # Find the nearest neighbors (songs) to this average vector\n",
    "        distances_for_eval, indices_for_eval = knn.kneighbors(playlist_vector_for_eval, n_neighbors=n_recs_for_eval + len(input_track_indices_for_eval))\n",
    "        \n",
    "        recommendations_for_eval = []\n",
    "        train_uris_for_eval = {idx_to_track[i] for i in input_track_indices_for_eval}\n",
    "        for idx_for_eval in indices_for_eval.flatten():\n",
    "            rec_uri_for_eval = idx_to_track[idx_for_eval]\n",
    "            # Add to recommendations if it's not in the original input (training set)\n",
    "            if rec_uri_for_eval not in train_uris_for_eval:\n",
    "                recommendations_for_eval.append(rec_uri_for_eval)\n",
    "        \n",
    "        return recommendations_for_eval[:n_recs_for_eval]\n",
    "\n",
    "    # --- 5. Evaluation --- \n",
    "    print(f\"Evaluating model with k={k}...\")\n",
    "    avg_precision = 0\n",
    "    avg_recall = 0\n",
    "    eval_count = 0\n",
    "\n",
    "    # Iterate through each playlist in our test set for evaluation\n",
    "    for user_idx, holdout_items in tqdm(test_set.items(), desc=\"Evaluating\"):\n",
    "        if len(holdout_items) == 0: # Skip playlists with no holdout items\n",
    "            continue\n",
    "\n",
    "        # Get recommendations for the current playlist\n",
    "        recommendations = _recommend_from_playlist_for_eval(user_idx, interaction_matrix_train, n_recs_for_eval=k)\n",
    "        \n",
    "        # Calculate precision and recall for this playlist and accumulate\n",
    "        avg_precision += precision_at_k(k, recommendations, holdout_items)\n",
    "        avg_recall += recall_at_k(k, recommendations, holdout_items)\n",
    "        eval_count += 1\n",
    "\n",
    "    # Calculate the average precision and recall across all evaluated playlists\n",
    "    avg_precision = avg_precision / eval_count if eval_count > 0 else 0\n",
    "    avg_recall = avg_recall / eval_count if eval_count > 0 else 0\n",
    "    \n",
    "    print(f\"Precision@{k}: {avg_precision:.4f}, Recall@{k}: {avg_recall:.4f}\")\n",
    "\n",
    "    # --- 6. Store Results --- \n",
    "    # Append the parameters and computed metrics to our global experiment_results list\n",
    "    experiment_results.append({\n",
    "        'slice_nums': slice_nums,\n",
    "        'data_size': len(playlists),\n",
    "        'n_components': n_components,\n",
    "        f'precision_at_{k}': avg_precision,\n",
    "        f'recall_at_{k}': avg_recall\n",
    "    })\n",
    "    print(\"--- Experiment Complete ---\n")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run Experiments\n",
    "\n",
    "Now you can easily run multiple experiments by calling the `run_experiment` function with different parameters. We'll loop through a few values for `n_components` to see how it affects performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear previous results if you are re-running experiments\n",
    "experiment_results = []\n",
    "\n",
    "# Example: Test n_components with values 50, 100, and 150 on the first data slice\n",
    "# You can change slice_nums to use more data (e.g., slice_nums=[0,1,2])\n",
    "component_options = [50, 100, 150]\n",
    "for n_comps in component_options:\n",
    "    run_experiment(slice_nums=[0], n_components=n_comps, k=10)\n",
    "\n",
    "# Uncomment and modify for more complex experiments, e.g., varying data size:\n",
    "# run_experiment(slice_nums=[0, 1], n_components=100, k=10)\n",
    "# run_experiment(slice_nums=[0, 1, 2, 3], n_components=150, k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualize Results\n",
    "\n",
    "After the experiments are complete, we can convert our results list into a pandas DataFrame and plot the outcome to easily see the impact of our changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not experiment_results:\n",
    "    print(\"No experiment results to plot. Please run some experiments first.\")\n",
    "else:\n",
    "    results_df = pd.DataFrame(experiment_results)\n",
    "    print(\"\n--- Experiment Results Summary ---")\n",
    "    print(results_df)\n",
    "    \n",
    "    # Create a plot to visualize the trend\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(results_df['n_components'], results_df['recall_at_10'], marker='o', label='Recall@10')\n",
    "    plt.plot(results_df['n_components'], results_df['precision_at_10'], marker='x', label='Precision@10')\n",
    "    \n",
    "    # Add labels, title, and legend for clarity\n",
    "    plt.title('Model Performance (Recall@10 & Precision@10) vs. Number of Components')\n",
    "    plt.xlabel('Number of Components (n_components)')\n",
    "    plt.ylabel('Score')\n",
    "    plt.grid(True)\n",
    "    plt.xticks(results_df['n_components']) # Ensure x-axis ticks match component options\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # You can also plot against data_size if you run experiments varying that parameter\n",
    "    # plt.figure(figsize=(10, 6))\n",
    "    # plt.plot(results_df['data_size'], results_df['recall_at_10'], marker='o')\n",
    "    # plt.title('Model Performance (Recall@10) vs. Data Size')\n",
    "    # plt.xlabel('Data Size (number of playlists)')\n",
    "    # plt.ylabel('Recall@10')\n",
    "    # plt.grid(True)\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save Your Best Model\n",
    "\n",
    "Once you've run your experiments and found the best parameters, you can run this final cell to re-train the model on your desired data and save the necessary artifacts for your API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION FOR FINAL MODEL --- \n",
    "BEST_N_COMPONENTS = 150  # <-- CHANGE THIS to the best value you found from your experiments\n",
    "SLICES_TO_TRAIN_ON = [0] # <-- CHANGE THIS to the slices you want to train the final model on (e.g., [0, 1, 2])\n",
    "\n",
    "# --- 1. Load Data and Mappings --- \n",
    "print(f\"Loading data from {len(SLICES_TO_TRAIN_ON)} slices for final training...\")\n",
    "data_path = '/Users/pabil/Downloads/spotify_million_playlist_dataset/data/'\n",
    "playlists = load_playlist_slice(data_path, slice_nums=SLICES_TO_TRAIN_ON)\n",
    "\n",
    "all_tracks = [track['track_uri'] for p in playlists for track in p['tracks']]\n",
    "unique_tracks = sorted(list(set(all_tracks)))\n",
    "track_to_idx = {track: i for i, track in enumerate(unique_tracks)}\n",
    "idx_to_track = {i: track for track, i in track_to_idx.items()}\n",
    "\n",
    "# For final model training, we use the entire dataset (no train-test split for this part)\n",
    "rows, cols = [], []\n",
    "pid_to_idx = {p['pid']: i for i, p in enumerate(playlists)}\n",
    "for p in playlists:\n",
    "    playlist_idx = pid_to_idx[p['pid']]\n",
    "    for track in p['tracks']:\n",
    "        if track['track_uri'] in track_to_idx:\n",
    "            rows.append(playlist_idx)\n",
    "            cols.append(track_to_idx[track['track_uri']])\n",
    "\n",
    "interaction_matrix = csr_matrix((np.ones(len(rows)), (rows, cols)), shape=(len(playlists), len(unique_tracks)))\n",
    "\n",
    "# --- 2. Train Final Models --- \n",
    "print(f\"Training final SVD model with n_components={BEST_N_COMPONENTS}...\")\n",
    "final_svd = TruncatedSVD(n_components=BEST_N_COMPONENTS, random_state=42)\n",
    "final_svd.fit(interaction_matrix) # Fit on the full interaction matrix\n",
    "\n",
    "print(\"Training final KNN model...\")\n",
    "track_embeddings = final_svd.components_.T\n",
    "final_knn = NearestNeighbors(n_neighbors=20, metric='cosine', algorithm='brute').fit(track_embeddings)\n",
    "\n",
    "# --- 3. Save Artifacts --- \n",
    "print(\"Saving model artifacts to .pkl files...\")\n",
    "joblib.dump(final_svd, 'svd_model.pkl')\n",
    "joblib.dump(final_knn, 'knn_model.pkl')\n",
    "joblib.dump(track_to_idx, 'track_to_idx.pkl')\n",
    "joblib.dump(idx_to_track, 'idx_to_track.pkl')\n",
    "\n",
    "print(\"\nArtifacts saved successfully!\")\n",
    "print(\"Remember to move these .pkl files to your '/model' directory.")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}